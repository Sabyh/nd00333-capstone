{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "import time\n",
    "import logging\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from azureml.core import Dataset, Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core import Workspace\n",
    "# ws = Workspace.create(name='mymlworkspace',\n",
    "#                       subscription_id='1e30ba0a-66fa-4479-9bca-95ba2cf71b20',    \n",
    "#                       resource_group='mymlexp',\n",
    "#                       create_resource_group=False,\n",
    "#                       location='eastus2' # or other supported Azure region  \n",
    "#                      )\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = 'automl-experiment'\n",
    "\n",
    "project_folder = './'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the configuration file.\n",
    "#ws.write_config()\n",
    "\n",
    "# Use this code to load the workspace from \n",
    "# other scripts and notebooks in this directory.\n",
    "# ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace.from_config()\n",
    "# # choose a name for the run history container in the workspace\n",
    "# experiment_name = 'automl-classifier'\n",
    "# # project folder\n",
    "\n",
    "import os\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(data=output, index=['']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster_name = \"AUTOML-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2',\n",
    "                                                           max_nodes=5)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 of importing dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Exclude the first 100 rows from training so that they can be used for test.\n",
    "X_train = digits.data[100:,:]\n",
    "y_train = digits.target[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "sample_size = 30\n",
    "plt.figure(figsize = (16, 6))\n",
    "for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x = 2, y = -2, s = y_train[i], fontsize = 18)\n",
    "    plt.imshow(X_train[i].reshape(8, 8), cmap = plt.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3 of importing dataset\n",
    "from azureml.core import Dataset\n",
    "from azureml.opendatasets import MNIST\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "mnist_file_dataset = MNIST.get_file_dataset()\n",
    "mnist_file_dataset.download(data_folder, overwrite=True)\n",
    "\n",
    "mnist_file_dataset = mnist_file_dataset.register(workspace=ws,\n",
    "                                                 name='mnist_opendataset',\n",
    "                                                 description='training and test dataset',\n",
    "                                                 create_new_version=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure utils.py is in the same directory as this code\n",
    "from utils import load_data\n",
    "import glob\n",
    "\n",
    "\n",
    "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the model converge faster.\n",
    "X_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
    "X_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
    "y_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n",
    "y_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n",
    "\n",
    "\n",
    "# now let's show some randomly chosen images from the traininng set.\n",
    "count = 0\n",
    "sample_size = 30\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in np.random.permutation(X_train.shape[0])[:sample_size]:\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x=10, y=-10, s=y_train[i], fontsize=18)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=plt.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws, 'mnist_opendataset')\n",
    "dataset.take(5).to_pandas_dataframe()\n",
    "data_train, data_test = dataset.random_split(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 of importing dataset\n",
    "from sklearn import datasets\n",
    "from azureml.core.dataset import Dataset\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a project_folder if it doesn't exist\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "if not os.path.exists('project_folder'):\n",
    "    os.makedirs('project_folder')\n",
    "\n",
    "X = pd.DataFrame(data_train.data[100:,:])\n",
    "y = pd.DataFrame(data_train.target[100:])\n",
    "\n",
    "# merge X and y\n",
    "label = \"digit\"\n",
    "X[label] = y\n",
    "\n",
    "training_data = X\n",
    "\n",
    "training_data.to_csv('data/digits.csv')\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='digitsdata', overwrite=True, show_progress=True)\n",
    "\n",
    "training_data = Dataset.Tabular.from_delimited_files(path=ds.path('digitsdata/digits.csv'))\n",
    "\n",
    "# data = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/machineData.csv\"\n",
    "# dataset = Dataset.Tabular.from_delimited_files(data)\n",
    "\n",
    "# # Split the dataset into train and test datasets\n",
    "# train_data, test_data = dataset.random_split(percentage=0.8, seed=223)\n",
    "\n",
    "# label = \"ERP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "import time\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"name\": \"AutoML_Demo_Experiment_{0}\".format(time.time()),\n",
    "    \"experiment_timeout_minutes\" : 20,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"max_concurrent_iterations\": 10,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automl_errors.log',\n",
    "                             path=project_folder,\n",
    "                             compute_target=compute_target,\n",
    "                             training_data=training_data,\n",
    "                             label_column_name=label,\n",
    "                             **automl_settings,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "##Local compute \n",
    "Automl_config = AutoMLConfig(task = 'classification',\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             max_time_sec = 12000,\n",
    "                             iterations = 20,\n",
    "                             compute_target=compute_target,\n",
    "                             n_cross_validations = 3,\n",
    "                             exit_score = 0.9985,\n",
    "                             blacklist_algos = ['kNN','LinearSVM'],\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             path=project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "local_run = experiment.submit(Automl_config, show_output=True)\n",
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = list(local_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "import pandas as pd\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./outputs', exist_ok=True)\n",
    "\n",
    "joblib.dump(fitted_model, filename='outputs/automl.joblib')\n",
    "\n",
    "model_name = best_run.properties['model_name']\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "best_run_metrics = best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "best_run_metrics = best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_file = 'score.py'\n",
    "\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the run with the highest accuracy value.\n",
    "# best_run, fitted_model = remote_run.get_output()\n",
    "\n",
    "# register model in workspace\n",
    "description = 'Automated Machine Learning Model'\n",
    "tags = None\n",
    "model1 = remote_run.register_model(model_name = model_name, description=description, tags=tags)\n",
    "remote_run.model_id # Use this id to deploy the model as a web service in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the run with the highest accuracy value.\n",
    "best_run, fitted_model = local_run.get_output()\n",
    "\n",
    "# register model in workspace\n",
    "description = 'Automated Machine Learning Model'\n",
    "tags = None\n",
    "model2 = local_run.register_model(model_name = model_name, description=description, tags=tags)\n",
    "local_run.model_id # Use this id to deploy the model as a web service in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 30 random samples from test set\n",
    "n = 30\n",
    "X_test = digits.data[:100, :]\n",
    "y_test = digits.target[:100]\n",
    "sample_indices = np.random.permutation(X_test.shape[0])[0:n]\n",
    "test_samples = X_test[sample_indices]\n",
    "\n",
    "\n",
    "# predict using the  model\n",
    "result = fitted_model.predict(test_samples)\n",
    "\n",
    "# compare actual value vs. the predicted values:\n",
    "i = 0\n",
    "plt.figure(figsize = (20, 1))\n",
    "\n",
    "for s in sample_indices:\n",
    "    plt.subplot(1, n, i + 1)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    \n",
    "    # use different color for misclassified sample\n",
    "    font_color = 'red' if y_test[s] != result[i] else 'black'\n",
    "    clr_map = plt.cm.gray if y_test[s] != result[i] else plt.cm.Greys\n",
    "    \n",
    "    plt.text(x = 2, y = -2, s = result[i], fontsize = 18, color = font_color)\n",
    "    plt.imshow(X_test[s].reshape(8, 8), cmap = clr_map)\n",
    "    \n",
    "    i = i + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.experiment import Experiment\n",
    "# experiment = Experiment(ws, 'Tutorial-automl-remote')\n",
    "# remote_run = experiment.submit(automl_config, show_output=True)\n",
    "remote_run.get_portal_url()\n",
    "env = best_run.get_environment()\n",
    "\n",
    "script_file = 'score.py'\n",
    "\n",
    "inference_config = InferenceConfig(entry_script = script_file, environment = env)\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "aci_service_name = 'automl-mnist-classifier'\n",
    "print(aci_service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(ws, aci_service_name, [model1], inference_config, aci_config)\n",
    "service.wait_for_deployment(True)\n",
    "print(\"State: \" + service.state)\n",
    "print(\"Scoring URI: \" + service.scoring_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}