{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Azure ML Experiment Submission\n",
        "\n",
        "To use this notebook, you need to download `config.json` file from Azure ML Workspace and place it in this folder. This will allow us to get the workspace reference right away:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    ws = Workspace.from_config()\n",
        "    print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
        "    print('Library configuration succeeded')\n",
        "except:\n",
        "    print('Workspace not found')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quick-starts-ws-133730\tsouthcentralus\taml-quickstarts-133730\tsouthcentralus\n",
            "Library configuration succeeded\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1609982074867
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then make sure we have the compute cluster. If the cluster does not exist - we will create it programmatically!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cluster_name = \"AUTOML-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2',\n",
        "                                                           max_nodes=5)\n",
        "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1609983469529
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating daatset in a file\r\n",
        "from sklearn.datasets import fetch_openml\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "print('fetching MNIST data...')\r\n",
        "mnist = fetch_openml('mnist_784')\r\n",
        "mnist['target'] = np.array([int(x) for x in mnist['target']])\r\n",
        "\r\n",
        "# use a random subset of n records to reduce training time.\r\n",
        "n = 20000\r\n",
        "shuffle_index = np.random.permutation(70000)[:n]\r\n",
        "X, y = mnist['data'][shuffle_index], mnist['target'][shuffle_index]\r\n",
        "\r\n",
        "os.makedirs('dataset',exist_ok=True)\r\n",
        "with open('dataset/mnist.pkl','wb') as f:\r\n",
        "    pickle.dump((X,y),f)\r\n",
        "\r\n",
        "print('Done')\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fetching MNIST data...\n",
            "Done\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609982852649
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now upload the MNIST dataset into the Azure ML Workspace:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ws.get_default_datastore()\n",
        "ds.upload('./dataset', target_path='mnist_data', overwrite=True, show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading ./dataset/mnist.pkl\n",
            "Uploaded ./dataset/mnist.pkl, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_b86733eee09c4d619819a4ca9907b5b5"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1609983348223
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #working on dataset for using it by registering dataset in azure datastore\n",
        "# from azureml.core.dataset import Dataset\n",
        "\n",
        "# web_path ='https://dprepdata.blob.core.windows.net/demo/Titanic.csv'\n",
        "# titanic_ds = Dataset.Tabular.from_delimited_files(path=web_path)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us create training script:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mytrain.py\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "from azureml.core import Run\n",
        "from azureml.core.model import Model\n",
        "import pickle\n",
        "import keras\n",
        "from keras.layers import Dense,Dropout\n",
        "\n",
        "parser = argparse.ArgumentParser(description='MNIST Train')\n",
        "parser.add_argument('--data_folder', type=str, dest='data_folder', help='data folder mounting point')\n",
        "parser.add_argument('--epochs', type=int, default=3)\n",
        "parser.add_argument('--batch_size', type=int, default=128)\n",
        "parser.add_argument('--dropout', type=float)\n",
        "parser.add_argument('--hidden', type=int, default=100)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "mnist_fn = os.path.join(args.data_folder, 'mnist_data','mnist.pkl')\n",
        "mnist_fn = 'dataset/mnist.pkl'\n",
        "with open(mnist_fn,'rb') as f:\n",
        "    X,y = pickle.load(f)\n",
        "\n",
        "X /= 255.0\n",
        "y = keras.utils.to_categorical(y,10)\n",
        "\n",
        "n = int(0.8*X.shape[0])\n",
        "x_train = X[0:n]\n",
        "y_train = y[0:n]\n",
        "x_test = X[n:]\n",
        "y_test = y[n:]\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(Dense(args.hidden,input_shape=(784,),activation='relu'))\n",
        "if args.dropout is not None and args.dropout<1:\n",
        "    model.add(Dropout(args.dropout))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=args.batch_size,\n",
        "          epochs=args.epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "os.makedirs('outputs',exist_ok=True)\n",
        "model.save('outputs/mnist_model.hdf5')\n",
        "\n",
        "# Log metrics\n",
        "run = Run.get_context()\n",
        "run.log('Test Loss', score[0])\n",
        "run.log('Accuracy', score[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mytrain.py\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's submit the experiment to run:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.train.estimator import Estimator\n",
        "\n",
        "experiment_name = 'Keras-MNIST'\n",
        "exp = Experiment(workspace=ws, name=experiment_name)\n",
        "script_params = {\n",
        "    '--data_folder': ws.get_default_datastore(),\n",
        "}\n",
        "\n",
        "est = Estimator(source_directory='.',\n",
        "                script_params=script_params,\n",
        "                compute_target=cluster,\n",
        "                entry_script='mytrain.py',\n",
        "                pip_packages=['keras','tensorflow']\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1609983494017
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(est)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
            "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n",
            "Submitting /mnt/batch/tasks/shared/LS_root/mounts/clusters/notebook133730/code/Users/odl_user_133730 directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1609983510177
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter optimization using Hyperdrive"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import *\n",
        "\n",
        "param_sampling = RandomParameterSampling({\n",
        "         '--hidden': choice([50,100,200,300]),\n",
        "         '--batch_size': choice([64,128]), \n",
        "         '--epochs': choice([5,10,50]),\n",
        "         '--dropout': choice([0.5,0.8,1])\n",
        "    })"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1609983514020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=0)\n",
        "hd_config = HyperDriveConfig(estimator=est,\n",
        "                            hyperparameter_sampling=param_sampling,\n",
        "                            policy=early_termination_policy,\n",
        "                            primary_metric_name='Accuracy',\n",
        "                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                            max_total_runs=16,\n",
        "                            max_concurrent_runs=4)\n",
        "experiment = Experiment(workspace=ws, name='keras-hyperdrive')\n",
        "hyperdrive_run = experiment.submit(hd_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
            "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1609983525631
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperdrive_run.cancel()\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(hyperdrive_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25705f04cfcb49e5b1b9f272fc14be41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/keras-hyperdrive/runs/HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137?wsid=/subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourcegroups/aml-quickstarts-133730/workspaces/quick-starts-ws-133730\", \"run_id\": \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137\", \"run_properties\": {\"run_id\": \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137\", \"created_utc\": \"2021-01-07T01:38:44.82382Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"8bffaf23-f533-49c7-9399-692ed52e6095\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"16\", \"max_total_jobs\": \"16\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"MEDIANSTOPPING\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0}}\", \"policy_config\": \"{\\\"name\\\": \\\"MEDIANSTOPPING\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--hidden\\\": [\\\"choice\\\", [[50, 100, 200, 300]]], \\\"--batch_size\\\": [\\\"choice\\\", [[64, 128]]], \\\"--epochs\\\": [\\\"choice\\\", [[5, 10, 50]]], \\\"--dropout\\\": [\\\"choice\\\", [[0.5, 0.8, 1]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--hidden\\\": [\\\"choice\\\", [[50, 100, 200, 300]]], \\\"--batch_size\\\": [\\\"choice\\\", [[64, 128]]], \\\"--epochs\\\": [\\\"choice\\\", [[5, 10, 50]]], \\\"--dropout\\\": [\\\"choice\\\", [[0.5, 0.8, 1]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourceGroups/aml-quickstarts-133730/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-133730/experiments/keras-hyperdrive\\\", \\\"SubscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-133730\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-133730\\\", \\\"ExperimentName\\\": \\\"keras-hyperdrive\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"mytrain.py\\\", \\\"arguments\\\": [\\\"--data_folder\\\", \\\"$AZUREML_DATAREFERENCE_workspaceblobstore\\\"], \\\"target\\\": \\\"AUTOML-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"keras\\\", \\\"tensorflow\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"workspaceblobstore\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": null, \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"8bffaf23-f533-49c7-9399-692ed52e6095\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"ed8f03e9-dca3-4536-868e-6013c8125c0e\\\", \\\"amlClientSessionId\\\": \\\"6bbf9360-af80-474b-82ef-f80760abddaf\\\", \\\"subscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"MedianStopping\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 16, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/f9d5a085-54dc-4215-9ba6-dad5d86e60a0/resourceGroups/aml-quickstarts-133730/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-133730/experiments/keras-hyperdrive\\\", \\\"SubscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-133730\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-133730\\\", \\\"ExperimentName\\\": \\\"keras-hyperdrive\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"mytrain.py\\\", \\\"arguments\\\": [\\\"--data_folder\\\", \\\"$AZUREML_DATAREFERENCE_workspaceblobstore\\\"], \\\"target\\\": \\\"AUTOML-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"keras\\\", \\\"tensorflow\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"workspaceblobstore\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": null, \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"8bffaf23-f533-49c7-9399-692ed52e6095\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"ed8f03e9-dca3-4536-868e-6013c8125c0e\\\", \\\"amlClientSessionId\\\": \\\"6bbf9360-af80-474b-82ef-f80760abddaf\\\", \\\"subscriptionId\\\": \\\"f9d5a085-54dc-4215-9ba6-dad5d86e60a0\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"MedianStopping\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 16, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-01-07T01:38:45.565612\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-01-07T01:38:45.565612\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"e08393a712c14570c03bf48a4914eaeab24ca59c120878248d5ab96e29c2814d\\\"\", \"progress_metadata_digest\": \"\\\"e08393a712c14570c03bf48a4914eaeab24ca59c120878248d5ab96e29c2814d\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-01-07T01:38:45.565612\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-01-07T01:38:45.565612\\\"\", \"_aml_system_HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_0\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 10, \\\"--hidden\\\": 50}\", \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_0\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 10, \\\"--hidden\\\": 50}\", \"_aml_system_HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_1\": \"{\\\"--batch_size\\\": 128, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 5, \\\"--hidden\\\": 200}\", \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_1\": \"{\\\"--batch_size\\\": 128, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 5, \\\"--hidden\\\": 200}\", \"_aml_system_HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_2\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 5, \\\"--hidden\\\": 300}\", \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_2\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 5, \\\"--hidden\\\": 300}\", \"_aml_system_HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_3\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 1, \\\"--epochs\\\": 5, \\\"--hidden\\\": 50}\", \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_3\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 1, \\\"--epochs\\\": 5, \\\"--hidden\\\": 50}\", \"_aml_system_environment_preparation_status\": \"PREPARING\", \"environment_preparation_status\": \"PREPARING\", \"_aml_system_prepare_run_id\": \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_preparation\", \"prepare_run_id\": \"HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137_preparation\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg133730.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_41cb025d-3c70-4a82-b8c2-3dbc7e91b137/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=I3pLyiXYzwX5rlQx4agLUT%2BS1Z8v2%2FISbpg605uVHcY%3D&st=2021-01-07T01%3A29%3A38Z&se=2021-01-07T09%3A39%3A38Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:01:14\", \"hyper_parameters\": {\"--hidden\": [\"choice\", [[50, 100, 200, 300]]], \"--batch_size\": [\"choice\", [[64, 128]]], \"--epochs\": [\"choice\", [[5, 10, 50]]], \"--dropout\": [\"choice\", [[0.5, 0.8, 1]]]}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2021-01-07T01:38:45.171834][API][INFO]Experiment created\\r\\n[2021-01-07T01:38:45.724404][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-01-07T01:38:46.099159][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-01-07T01:38:46.4505885Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1609983578770
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Registrering the Best Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "print(best_run)\n",
        "print('Best accuracy: {}'.format(best_run_metrics['Accuracy']))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: keras-hyperdrive,\n",
            "Id: keras-hyperdrive_1575928171879731_15,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed)\n",
            "Best accuracy: 0.9702500104904175\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run.register_model(model_name='mnist_keras', model_path='outputs/mnist_model.hdf5')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='AzMLWorkspace', subscription_id='d04ba089-715a-45b1-b4a3-2ce0fd60316f', resource_group='AzureMLGroup'), name=mnist_keras, id=mnist_keras:1, version=1, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}